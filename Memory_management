import os
os.environ['OPENAI_API_KEY']='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'
from langchain.llms import  OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
llm=OpenAI(temperature=0.7)

prompt_template_name=PromptTemplate(input_variables=['cricket'],
               template="who won the {cricket} world cup in the year 2001")


name_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key="Won by:")
print(name_chain.run("Cricket"))

print(type(name_chain.memory))


from langchain.memory import ConversationBufferMemory

memory=ConversationBufferMemory()

name_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key="Won by:",memory=memory)  //passing memory as a parameter allows chain used to answer questions related to pervious once.
ConversationChain allows bot display previously asked questions in the chat window.
ConversationBufferMemory allows us to restirct the window of interaction.
print(name_chain.run("Cricket"))
print(name_chain.run("fifa"))
print(("memory attached :" ,name_chain.memory))

from langchain.chains import ConversationChain



//ConversationChain allows bot display previously asked questions in the chat window.

convo=ConversationChain(llm=OpenAI(temperature=0.7))
print("conversation:" ,convo.prompt)
convo.run("5+5=?")
convo.run("who is the president of india?")

print(convo.memory.to_json)


//as it is remembering everything we need to restrict the window as cost is assosicated with it

//ConversationBufferMemory allows us to restirct the window of interaction.
from langchain.memory import ConversationBufferWindowMemory

memory=ConversationBufferWindowMemory(k=1)    // k parameter helps in restriting the window of questions that needs to be stored.

convo=ConversationChain(llm=OpenAI(temperature=0.7))

convo.run("5+5=?")
convo.run("who is the president of india?")
convo.run("5-5=?")
print(convo.memory)
